{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e830f-4f06-4bc7-adb0-c6e45a9828a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from sklearn import tree\n",
    "from collections import namedtuple\n",
    "\n",
    "class maxFlowOptimalDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=3, alpha=0, warmstart=True, timelimit=600, output=True):\n",
    "        self.max_depth = max_depth\n",
    "        self.alpha = alpha\n",
    "        self.warmstart = warmstart\n",
    "        self.timelimit = timelimit\n",
    "        self.output = output\n",
    "        self.trained = False\n",
    "        self.optgap = None\n",
    "        self.leaf_counts = {}\n",
    "\n",
    "        # Tree structure definitions\n",
    "        self.B = list(range(2**self.max_depth - 1))  # Branch nodes\n",
    "        self.T = list(range(2**self.max_depth - 1, 2**(self.max_depth + 1) - 1))  # Leaf nodes\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.n, self.m = x.shape\n",
    "        if self.output:\n",
    "            print(f'Training data include {self.n} instances, {self.m} features.')\n",
    "\n",
    "        self.K = list(range(np.max(y) + 1))\n",
    "        self.I = list(range(self.n))\n",
    "        self.F = list(range(self.m))\n",
    "\n",
    "        m, b, w = self._buildMIP(x, y)\n",
    "        if self.warmstart:\n",
    "            self._setStart(x, y, b, w)\n",
    "        m.optimize()\n",
    "        self.optgap = m.MIPGap\n",
    "\n",
    "        # Retrieve solution values\n",
    "         # Retrieve solution values\n",
    "        z_val = m.getAttr('x', m._z)\n",
    "        self._zval = z_val  # Gem lÃ¸sning i objektet til senere brug\n",
    "        \n",
    "        self._tree_construction(m, b, w)\n",
    "        # Beregn korrekt klassificerede (match mellem bladets label og y[i])\n",
    "        correct = sum(\n",
    "            z_val[i, n] >= 0.5 and self.labels.get(n) == y[i]\n",
    "            for i in self.I for n in self.T\n",
    "        )\n",
    "        accuracy = correct / len(self.I)\n",
    "\n",
    "        # Antal data i hvert blad\n",
    "        self.leaf_counts = {\n",
    "            n: sum(z_val[i, n] >= 0.5 for i in self.I)\n",
    "            for n in self.T\n",
    "        }\n",
    "\n",
    "        # Fordeling af klasser i hvert blad\n",
    "        from collections import Counter\n",
    "        self.leaf_class_distribution = {\n",
    "            n: Counter(y[i] for i in self.I if z_val[i, n] >= 0.5)\n",
    "            for n in self.T\n",
    "        }\n",
    "\n",
    "        # Udskrivning\n",
    "        if self.output:\n",
    "            print(f\"Correctly classified: {correct}/{len(self.I)} ({accuracy:.2%})\")\n",
    "        \n",
    "            print(\"\\nAntal data i hvert blad:\")\n",
    "            for n, count in self.leaf_counts.items():\n",
    "                print(f\"  Leaf {n}: {count} data points\")\n",
    "        \n",
    "            print(\"\\nKlassedistribution i hvert blad:\")\n",
    "            for n, dist in self.leaf_class_distribution.items():\n",
    "                print(f\"  Leaf {n}: {dict(dist)}\")\n",
    "\n",
    "\n",
    "        self.trained = True\n",
    "\n",
    "    def _buildMIP(self, x, y):\n",
    "        m = gp.Model(\"StrongOCT\")\n",
    "        m.Params.outputFlag = self.output\n",
    "        m.Params.LogToConsole = self.output\n",
    "        m.Params.timelimit = self.timelimit\n",
    "        m.Params.threads = 0\n",
    "        #m.Params.MIPFocus = 1  # Focus on feasibility\n",
    "        #m.Params.Presolve = 2   # Aggressive presolve\n",
    "\n",
    "        # Variables\n",
    "        b = m.addVars(self.B, self.F, vtype=gp.GRB.BINARY, name=\"b\")\n",
    "        w = m.addVars(self.T, self.K, vtype=gp.GRB.BINARY, name=\"w\")\n",
    "        z = m.addVars(self.I, self.B + self.T, vtype=gp.GRB.BINARY, name=\"z\")\n",
    "\n",
    "        # Constraint (1b): Each branch node selects exactly one feature\n",
    "        m.addConstrs((b.sum(n, '*') == 1 for n in self.B))\n",
    "\n",
    "        # Flow constraints\n",
    "        for i in self.I:\n",
    "            # Root node must be visited by all instances\n",
    "            m.addConstr(z[i, 0] == 1)  # Fixed: must be == 1\n",
    "            \n",
    "            # Branch node flow conservation\n",
    "            for n in self.B:\n",
    "                l, r = self._tree_children(n)\n",
    "                m.addConstr(z[i, n] == z[i, l] + z[i, r])\n",
    "            for i in self.I:\n",
    "                for n in self.B:\n",
    "                    l, r = self._tree_children(n)\n",
    "                    # Features where x_i[f] == 0\n",
    "                    features_zero = [f for f in self.F if x[i][f] == 0]\n",
    "                    m.addConstr(z[i, l] <= gp.quicksum(b[n, f] for f in features_zero))\n",
    "                    # Features where x_i[f] == 1\n",
    "                    features_one = [f for f in self.F if x[i][f] == 1]\n",
    "                    m.addConstr(z[i, r] <= gp.quicksum(b[n, f] for f in features_one))\n",
    "\n",
    "            # Leaf node constraints\n",
    "            for n in self.T:\n",
    "                parent = (n - 1) // 2\n",
    "                if parent in self.B:\n",
    "                    m.addConstr(z[i, parent] >= z[i, n], name=f\"leaf_flow_lower_{i}_{n}\")  # z_p >= z_n\n",
    "                    #m.addConstr(z[i, parent] <= z[i, n] + (1 - w[n, y[i]]),\n",
    "            #name=f\"leaf_flow_upper_{i}_{n}\")  # z_p <= z_n if w = 1\n",
    "\n",
    "                m.addConstr(z[i, n] <= w[n, y[i]], name=f\"label_match_{i}_{n}\")\n",
    "\n",
    "        # Constraint: Each leaf assigns exactly one class\n",
    "        m.addConstrs((w.sum(n, '*') == 1 for n in self.T))\n",
    "\n",
    "        # Objective: Maximize correct classifications - regularization\n",
    "        obj = gp.quicksum(z[i, n] for i in self.I for n in self.T) - self.alpha * b.sum()\n",
    "        m.setObjective(obj, gp.GRB.MAXIMIZE)\n",
    "\n",
    "        # Store variables for warm start\n",
    "        m._b = b\n",
    "        m._w = w\n",
    "        m._z = z\n",
    "        m._X = x\n",
    "        m._Y = y\n",
    "\n",
    "        return m, b, w\n",
    "\n",
    "    def predict(self, x):\n",
    "        if not self.trained:\n",
    "            raise AssertionError('Model not trained yet.')\n",
    "\n",
    "        pred = []\n",
    "        for val in x:\n",
    "            n = 0\n",
    "            while n in self.branches:  # Traverse until reaching a leaf\n",
    "                f = self.branches.get(n, 0)  # Safely handle missing branches\n",
    "                n = 2 * n + 1 if val[f] == 0 else 2 * n + 2\n",
    "            pred.append(self.labels.get(n, 0))  # Safely handle missing labels\n",
    "        return np.array(pred)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tree_children(node):\n",
    "        return 2 * node + 1, 2 * node + 2\n",
    "\n",
    "    def _tree_construction(self, m, b, w):\n",
    "        b_val = m.getAttr('x', b)\n",
    "        w_val = m.getAttr('x', w)\n",
    "        \n",
    "        # Extract branch decisions with safety checks\n",
    "        self.branches = {}\n",
    "        for n in self.B:\n",
    "            for f in self.F:\n",
    "                if b_val[n, f] >= 0.999:  # Considered as binary\n",
    "                    self.branches[n] = f\n",
    "                    break\n",
    "        \n",
    "        # Extract leaf class assignments with safety checks\n",
    "        self.labels = {}\n",
    "        for n in self.T:\n",
    "            for k in self.K:\n",
    "                if w_val[n, k] >= 0.999:\n",
    "                    self.labels[n] = k\n",
    "                    break\n",
    "\n",
    "    def _setStart(self, x, y, b, w):\n",
    "        # Warm start from standard decision tree\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "        clf.fit(x, y)\n",
    "        rules = self._getRules(clf)\n",
    "\n",
    "        # Set feature splits with safety checks\n",
    "        for n in self.B:\n",
    "            if rules[n].feat is not None and rules[n].feat >= 0:\n",
    "                try:\n",
    "                    feat = int(rules[n].feat)\n",
    "                    b[n, feat].start = 1\n",
    "                    for f in self.F:\n",
    "                        if f != feat:\n",
    "                            b[n, f].start = 0\n",
    "                except (ValueError, TypeError, IndexError):\n",
    "                    continue  # Skip invalid conversions\n",
    "\n",
    "        # Set leaf class assignments with safety checks\n",
    "        for n in self.T:\n",
    "            if rules[n].value is not None:\n",
    "                try:\n",
    "                    # scikit-learn's value is shaped (1, n_classes)\n",
    "                    leaf_class = np.argmax(rules[n].value[0])  \n",
    "                    for k in self.K:\n",
    "                        w[n, k].start = 1 if k == leaf_class else 0\n",
    "                except (ValueError, TypeError, IndexError):\n",
    "                    continue  # Skip invalid assignments\n",
    "\n",
    "    def _getRules(self, clf):\n",
    "        node_map = {0: 0}\n",
    "        for n in self.B:\n",
    "            mapped = node_map.get(n, -1)\n",
    "            if mapped == -1 or mapped >= clf.tree_.node_count:\n",
    "                continue\n",
    "            left = clf.tree_.children_left[mapped]\n",
    "            right = clf.tree_.children_right[mapped]\n",
    "            node_map[2*n + 1] = left\n",
    "            node_map[2*n + 2] = right\n",
    "\n",
    "        rule = namedtuple('Rules', ('feat', 'threshold', 'value'))\n",
    "        rules = {}\n",
    "        for n in self.B + self.T:\n",
    "            mapped = node_map.get(n, -1)\n",
    "            if mapped == -1 or mapped >= clf.tree_.node_count:\n",
    "                rules[n] = rule(None, None, None)\n",
    "            else:\n",
    "                feat = clf.tree_.feature[mapped]\n",
    "                rules[n] = rule(\n",
    "                    feat if feat >= 0 else None,\n",
    "                    clf.tree_.threshold[mapped] if feat >= 0 else None,\n",
    "                    clf.tree_.value[mapped, 0] if feat >= 0 else None\n",
    "                )\n",
    "        return rules\n",
    "\n",
    "    def get_leaf_counts(self):\n",
    "        \"\"\"Return dictionary of leaf node counts\"\"\"\n",
    "        if not self.trained:\n",
    "            raise AssertionError(\"Model not trained yet.\")\n",
    "        return self.leaf_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
