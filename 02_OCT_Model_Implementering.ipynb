{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4abf3-be07-4ddc-a822-b810e2d633b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "from sklearn import tree\n",
    "from gurobipy import GRB\n",
    "from scipy import stats #bruges til stats.mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "class OCT:\n",
    "\n",
    "  def __init__(self, max_depth, min_samples_leaf, alpha, warmstart=True, timelimit=600, output = True):\n",
    "    self.max_depth = max_depth\n",
    "    self.min_samples_leaf = min_samples_leaf                              # minimum antal datapunkter i enhver slutnode\n",
    "    self.alpha = alpha\n",
    "    self.warmstart = warmstart\n",
    "    self.output = output\n",
    "    self.timelimit = timelimit\n",
    "    self.trained = False\n",
    "    self.optgap = None\n",
    "\n",
    "#Indekserer over nodes\n",
    "    self.index_nodes = [t+1 for t in range(2**(self.max_depth + 1) -1)]                                         # Nodes\n",
    "    self.index_branch_nodes = [t+1 for t in range(math.floor(max(self.index_nodes)/2))]                         # Branch nodes\n",
    "    self.index_leaf_nodes = [t+1 for t in range(math.floor(max(self.index_nodes)/2), max(self.index_nodes))]    # Leaf nodes\n",
    "\n",
    "\n",
    "  def fit(self, x, y):\n",
    "# Bestemmer datasættets størrelse\n",
    "    self.n, self.p = x.shape           # self.n = antal datapunkter (rækker), self.p = antal features (kolonner)\n",
    "\n",
    "    if self.output:\n",
    "        print('Training data include {} instances, {} features.'.format(self.n,self.p)) #If true: Output = (observationer,indgange)\n",
    "\n",
    "# Gemmer de unikke klasser (labels) i datasættet\n",
    "    self.labels = np.unique(y)\n",
    "\n",
    "# Skalering af data\n",
    "    self.scales = np.max(x, axis=0)     #Finder den maksimale værdi for hver feature (kolonne)\n",
    "    self.scales[self.scales == 0] = 1   #Hvis der findes maks-værdier på 0, erstattes de med 1 for at undgå divison med 0 senere\n",
    "\n",
    "\n",
    "#Løser Mixed Integer Programming (MIP) modellen\n",
    "    m, a, b, c, d, z, l = self._buildMIP(x/self.scales, y)\n",
    "    if self.warmstart:\n",
    "          self._setStart(x, y, a, c, d, l)\n",
    "    m.optimize()\n",
    "    self.optgap = m.MIPGap # MIP-gapet er forskellen mellem den bedste løsning, der er fundet indtil videre, og den bedste mulige løsning.\n",
    "\n",
    "\n",
    "#Gemmer de optimerede værdier for variablerne i dictionaries\n",
    "    self._a = {ind:a[ind].x for ind in a}       \n",
    "    self._b = {ind:b[ind].x for ind in b}\n",
    "    self._c = {ind:c[ind].x for ind in c}\n",
    "    self._d = {ind:d[ind].x for ind in d}\n",
    "    self._z = {ind:z[ind].x for ind in z}\n",
    "    self._l = {ind:l[ind].x for ind in l}\n",
    "\n",
    "    self.trained = True\n",
    "\n",
    "\n",
    "  def predict(self, x):\n",
    "       # Tjekker om modellen er trænet\n",
    "        if not self.trained:\n",
    "            raise AssertionError('Denne optimalDecisionTreeClassifier-instans er endnu ikke trænet.') #Hvis modellen ikke er trænet (fitted), kommer denne besked.\n",
    "\n",
    " # Opretter en dictionary til at mappe hver leaf node til en label\n",
    "        labelmap = {}                                 #Opretter en tom dictionary til at tildele labels til hver leaf node\n",
    "        for t in self.index_leaf_nodes:               #Gennemløber alle leaf nodes\n",
    "            for k in self.labels:                     #Gennemløber alle mulige klasser\n",
    "                if self._c[k,t] >= 1e-2:              #Hvis c[k, t] indikerer, at leaf node t har klasse k\n",
    "                   labelmap[t] = k\n",
    "\n",
    "        y_pred = []                                   ## Initialiserer en tom liste til at gemme de forudsagte labels for hvert datapunkt\n",
    "        for xi in x/self.scales:                      # Gennemløber hvert datapunkt ét ad gangen                                  \n",
    "            t = 1                                     #Starter i root node (node 1)\n",
    "            while t not in self.index_leaf_nodes:     # Mens vi ikke er i en leaf node\n",
    "                right = (sum([self._a[j,t] * xi[j] for j in range(self.p)]) + 1e-9 >= self._b[t])\n",
    "                if right:\n",
    "                    t = 2 * t + 1                     # Går til højre barn (ulige indeks)\n",
    "            \n",
    "                else:\n",
    "                    t = 2 * t                         # Går til venstre barn (lige indeks)\n",
    "\n",
    "                    # label\n",
    "            y_pred.append(labelmap[t])                # Når vi er i en leaf node, gemmes den forudsagte klasse\n",
    "\n",
    "        return np.array(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "  def _buildMIP(self, x, y):\n",
    "    m = gp.Model()                            # Opretter en ny Gurobi-model m\n",
    "\n",
    "    m.Params.outputFlag = self.output               #Bestemmer om løsningsoutput skal vises\n",
    "    m.Params.LogToConsole = self.output             #Kontrolerer om logging information fra solveren vises\n",
    "    # time limit\n",
    "    m.Params.timelimit = self.timelimit\n",
    "    # parallel\n",
    "    m.params.threads = 0                            #tillader solveren at bestemme det optimale antal threads og vi maksimerer performance\n",
    "    #m.params.MIPFocus=2\n",
    "\n",
    "\n",
    "\n",
    "    m.modelSense = GRB.MINIMIZE                     # Her minimerer vi objektfunktionen\n",
    "\n",
    "\n",
    "# Variables\n",
    "    a = m.addVars(self.p, self.index_branch_nodes, vtype=GRB.BINARY, name='a')        # splitting feature: over indgang, branchnodes\n",
    "    d = m.addVars(self.index_branch_nodes, vtype=GRB.BINARY, name='d')                # giver 1, hvis node t splitter og 0 hvis ikke\n",
    "    b = m.addVars(self.index_branch_nodes, vtype=GRB.CONTINUOUS, name='b')            # højresiden, når vi splitter\n",
    "    z = m.addVars(self.n, self.index_leaf_nodes, vtype=GRB.BINARY, name='z')          # leaf node assignment\n",
    "    l = m.addVars(self.index_leaf_nodes, vtype=GRB.BINARY, name='l')                  # giver 1, hvis der er mindst et punkt i bladet og 0 ellers\n",
    "    N = m.addVars(self.labels, self.index_leaf_nodes, vtype=GRB.CONTINUOUS, name='Nkt') # antal punkter med klasse k i blad t\n",
    "    Nt = m. addVars(self.index_leaf_nodes, vtype=GRB.CONTINUOUS, name='Nt')             # samlet antal punkter i node t\n",
    "    c = m.addVars(self.labels, self.index_leaf_nodes, vtype=GRB.BINARY, name='c')     # giver 1, hvis label k er givet til blad t og 0 ellers\n",
    "    L = m.addVars(self.index_leaf_nodes, vtype=GRB.CONTINUOUS, name='l')              # antal datapunkter misklassificeret i blad t\n",
    "\n",
    "\n",
    "\n",
    "    # calculate baseline accuracy\n",
    "    Lhat = self._calLhat(y)                      # beregner baseline-værdien på klasse y\n",
    "\n",
    "\n",
    "    # epsilon\n",
    "    epsilon = self._epsilon(x)\n",
    "\n",
    "    # objektfunktion\n",
    "    obj = L.sum() / Lhat + self.alpha * d.sum()\n",
    "    m.setObjective(obj)\n",
    "\n",
    "# Bibetingelser\n",
    "    #(4.1)\n",
    "    m.addConstrs(a.sum('*', t) == d[t] for t in self.index_branch_nodes) #For hver branch node t skal summen af a_jt være lige d_t hvilket sikrer, at hver branch node\n",
    "                                                                         # foretager præcis et split, hvir den er aktiv\n",
    "    #(4.2)\n",
    "    m.addConstrs(b[t] <= d[t] for t in self.index_branch_nodes) # 0 <= b_t <= d_t for alle branch nodes t\n",
    "    #(4.3)---?\n",
    "    m.addConstrs(d[t] <= d[t//2] for t in self.index_branch_nodes if t != 1) # En branch node kan kun være aktiv, hvis dens parent node også er aktiv.\n",
    "                                                                             # Root node (t=1) har ingen parent, så den undtages, t//2 giver t/2 og så runder den ned til nærmeste heltal\n",
    "    #(4.5)\n",
    "    m.addConstrs(z[i,t] <= l[t] for t in self.index_leaf_nodes for i in range(self.n)) #z_it <= l_t for alle leaf nodes t og for alle i=1,..,n\n",
    "    #(4.6)\n",
    "    m.addConstrs(z.sum('*', t) >= self.min_samples_leaf * l[t] for t in self.index_leaf_nodes) #summen af z_it >= N_min * l_t for alle leaf nodes t\n",
    "    #(4.7)\n",
    "    m.addConstrs(z.sum(i, '*') == 1 for i in range(self.n)) #summen af z_it (over alle leaf nodes t) skal være lig med 1 for alle i=1,...,N (hvert punkt tildeles 1 leaf node)\n",
    "    #(4.15) og (4.16)\n",
    "    for t in self.index_leaf_nodes:\n",
    "            left = (t % 2 == 0)           #Tjekker om t er venstre barn (lige tal) (% betyder, at restleddet efter division er 0)\n",
    "            t_anc = t // 2                #Finder parent node til t\n",
    "            while t_anc != 0:             #Kigger ikke på root node, da 1//2 = 0\n",
    "                if left:\n",
    "                    m.addConstrs(gp.quicksum(a[j,t_anc] * (x[i,j] + epsilon[j]) for j in range(self.p))\n",
    "                                 +\n",
    "                                 (1 + np.max(epsilon)) * (1 - d[t_anc]) \n",
    "                                 <=\n",
    "                                 b[t_anc] + (1 + np.max(epsilon)) * (1 - z[i,t])\n",
    "                                 for i in range(self.n))\n",
    "                else:\n",
    "                    m.addConstrs(gp.quicksum(a[j,t_anc] * x[i,j] for j in range(self.p))\n",
    "                                 >=\n",
    "                                 b[t_anc] - (1 - z[i,t])\n",
    "                                 for i in range(self.n))\n",
    "                left = (t_anc % 2 == 0)   #Opdater om vi er venstre eller højre barn\n",
    "                t_anc //= 2               #Opdaterer til parent node for den node, man lige har behandlet, og bevæger sig på den måde op gennem træstrukturen\n",
    "                                          # = denne gør at t_anc defineres på ny\n",
    "    #(4.17)\n",
    "    m.addConstrs(gp.quicksum((y[i] == k) * z[i,t] for i in range(self.n)) == N[k,t] for t in self.index_leaf_nodes for k in self.labels)\n",
    "    #Summerer alle datapunkter med label k (y_ik) hvis datapunkt i er i leaf node t. Finder samlet antal datapunkter med label k i leaf node t\n",
    "    #(2.19)\n",
    "    m.addConstrs(z.sum('*', t) == Nt[t] for t in self.index_leaf_nodes) #Samlet antal punkter i leaf node t er lig med summen af z_it over i\n",
    "    #(2.21)\n",
    "    m.addConstrs(c.sum('*', t) == l[t] for t in self.index_leaf_nodes) #node t får kun et label k hvis den indeholder punkter, altså hvis l_t=1, ellers c_kt=0=l_t\n",
    "\n",
    "    #For (4.23) og (4.24) er N_t=Nt[t], N_kt=N[k,t] og M=n=antal datapunkter (her self.n). Dette er lineariseringsbetingelserne\n",
    "    #(4.23)\n",
    "    m.addConstrs(L[t] >= Nt[t] - N[k,t] - self.n * (1 - c[k,t]) for t in self.index_leaf_nodes for k in self.labels)\n",
    "    #(4.24)\n",
    "    m.addConstrs(L[t] <= Nt[t] - N[k,t] + self.n * c[k,t] for t in self.index_leaf_nodes for k in self.labels)\n",
    "\n",
    "    return m, a, b, c, d, z, l\n",
    "\n",
    "  @staticmethod\n",
    "  def _calLhat(y):\n",
    "    mode = stats.mode(y)[0]                         # vælger den klasse, der går hyppigst igen i datasættet\n",
    "    return np.sum(y == mode)                       # beregner baseline-værdien på klasse y\n",
    "\n",
    "\n",
    "\n",
    "  def _epsilon(self,x):\n",
    "    epsilon = []\n",
    "    # Gennemløber hver feature (kolonne) i datasættet\n",
    "    for j in range(x.shape[1]):\n",
    "        xj = x[:,j]                                 # løber igennem alle observationer for et j\n",
    "        xj = np.unique(xj)                          # Fjerner duplikater så vi kun har unikke værdier\n",
    "        xj = np.sort(xj)[::-1]                      # Sorterer værdierne fra høj til lav\n",
    "        dis = [1]\n",
    "        for i in range(len(xj)-1):                  # for x_j gennemløbes alle observationer (over i)\n",
    "          dis.append(xj[i] - xj[i+1])               # den laver en liste med alle afstandene, dvs. xj[1]-xj[2], xj[2]-xj[3]\n",
    "        #Tilføjer den mindste afstand (eller 1 hvis minimum er 0) for denne feature\n",
    "        epsilon.append(np.min(dis) if np.min(dis) else 1)\n",
    "    return epsilon\n",
    "\n",
    "\n",
    "  def _setStart(self, x, y, a, c, d, l):\n",
    "        \"\"\"\n",
    "        set warm start from CART\n",
    "        \"\"\"\n",
    "        # Træner et Decision Tree (CART) på data\n",
    "        if self.min_samples_leaf > 1:\n",
    "            clf = tree.DecisionTreeClassifier(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf)\n",
    "        else:\n",
    "            clf = tree.DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "        clf.fit(x, y)\n",
    "\n",
    "        # Henter splitting-regler fra CART træet\n",
    "        rules = self._getRules(clf)               \n",
    "\n",
    "        # Fixer startværdier for branch nodes\n",
    "        for t in self.index_branch_nodes:\n",
    "                                                  #Hvis den ikke splitter\n",
    "            if rules[t].feat is None or rules[t].feat == tree._tree.TREE_UNDEFINED:\n",
    "                d[t].start = 0                    # Sætter d[t] = 0 (noden splitter ikke)\n",
    "\n",
    "                for j in range(self.p):\n",
    "                    a[j,t].start = 0\n",
    "            # Hvis noden splitter\n",
    "            else:\n",
    "                d[t].start = 1                    #ellers sættes d[t]=1\n",
    "                for j in range(self.p):\n",
    "                    if j == int(rules[t].feat):\n",
    "                        a[j,t].start = 1          #a[j,t]  sættes til 1 hvis der splittes på feature j\n",
    "                    else:\n",
    "                        a[j,t].start = 0          #a[j,t]  sættes til 0 for alle j der ikke angiver et split\n",
    "\n",
    "        # Fixer værdier for leaf nodes\n",
    "        for t in self.index_leaf_nodes:           #gennemløber alle leaf nodes t\n",
    "            # # Tjekker om vi skal afslutte tidligt (ingen datapunkter i denne node)\n",
    "            if rules[t].value is None:            #Hvis værdien er None, er der ingen datapunkter i denne leaf node\n",
    "                l[t].start = int(t % 2)\n",
    "                # Hvis vi er på højre gren (ulige t)\n",
    "                if t % 2:\n",
    "                    t_leaf = t\n",
    "                    while rules[t].value is None:     #hvis None, sættes l(t)=0 for lige t og l(t)=1 for ulige t\n",
    "                        t //= 2\n",
    "                    for k in self.labels:\n",
    "                        if k == np.argmax(rules[t].value):\n",
    "                            c[k, t_leaf].start = 1     #Når l(t) for leaf node t ikke er none, er der datapunkter i leaf node t og den tildeles et label\n",
    "                        else:\n",
    "                            c[k, t_leaf].start = 0\n",
    "                # Hvis vi er på venstre gren (lige t)\n",
    "                else:\n",
    "                    for k in self.labels:\n",
    "                        c[k, t].start = 0\n",
    "            #  Hvis leaf node har datapunkter\n",
    "            else:\n",
    "                l[t].start = 1\n",
    "                for k in self.labels:\n",
    "                    if k == np.argmax(rules[t].value):\n",
    "                        c[k, t].start = 1\n",
    "                    else:\n",
    "                        c[k, t].start = 0\n",
    "\n",
    "  def _getRules(self, clf):\n",
    "        \"\"\"\n",
    "        get splitting rules from a fitted CART tree\n",
    "        \"\"\"\n",
    "        # opretter en map fra egne node-indekser(1,2,3,.....)\n",
    "        node_map = {1:0}\n",
    "        #gennemløber alle branch nodes i vores træ\n",
    "        for t in self.index_branch_nodes:\n",
    "            # antager først, at begge child nodes(venstre og højre er terminale(ingen børn))\n",
    "            node_map[2*t] = -1\n",
    "            node_map[2*t+1] = -1\n",
    "            # Finder venstre barn i CART træet og opdaterer node_map\n",
    "            l = clf.tree_.children_left[node_map[t]]\n",
    "            node_map[2*t] = l\n",
    "            # Finder højre barn i CART træet og opdaterer node_map\n",
    "            r = clf.tree_.children_right[node_map[t]]\n",
    "            node_map[2*t+1] = r\n",
    "\n",
    "\n",
    "  # Opretter en struktur 'Rules', der gemmer information om split:feature, threshold og value\n",
    "        rule = namedtuple('Rules', ('feat', 'threshold', 'value'))\n",
    "        rules = {}\n",
    "        # Gennemløber alle branch nodes\n",
    "        for t in self.index_branch_nodes:\n",
    "            i = node_map[t]\n",
    "            if i == -1:\n",
    "                #Hvis der ikke er nogen node(terminal), gemmes None for split-information\n",
    "                r = rule(None, None, None)\n",
    "            else:\n",
    "                r = rule(clf.tree_.feature[i], clf.tree_.threshold[i], clf.tree_.value[i,0])\n",
    "            rules[t] = r\n",
    "        # leaf nodes\n",
    "        for t in self.index_leaf_nodes:\n",
    "            i = node_map[t]\n",
    "            if i == -1:\n",
    "                r = rule(None, None, None)\n",
    "            else:\n",
    "                #Ellers gemmes featur og threshold\n",
    "                r = rule(None, None, clf.tree_.value[i,0])\n",
    "            rules[t] = r\n",
    "\n",
    "        return rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
